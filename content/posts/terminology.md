---
title: "常见AI应用术语解释"
date: ""
excerpt: "深入解析AI应用开发中的关键术语和方案，包括Rules、MCP、Function Calling、Agent Skills"
readTime: "12分钟阅读"
---

# Function Calling

## 1. 解决了什么问题？

先把人话说在前面：**大模型很会“聊天”，但它不会“动手干活”**。  
Function Calling（也叫“工具/函数调用”）的作用，就是让模型在需要时**别瞎猜**，而是**叫外部工具去查/去算/去执行**，最后再把结果用自然语言讲给你听。

如果没有 Function Calling，你经常会遇到这些坑：

1. 信息不新：你问“现在天气/刚发生的新闻”，模型可能只能凭旧知识硬答。
2. 算不准：你让它做精确计算、查数据库、走严格流程，它可能给出“看着像对，其实不对”的结果（俗称幻觉）。
3. 只会说不会做：它可以“建议你怎么发邮件/怎么买票”，但没法真的替你点按钮、读文件、调接口。

**核心转变：从“文本生成”到“意图识别”**
有了 Function Calling 后，模型会先想一件事：**这题我是不是应该去“查一下/算一下/做一下”？**  
如果答案是“应该”，它就会给你的程序一张“小纸条”（结构化指令）：**要用哪个工具、带什么参数**，让程序去执行，拿到真实结果再回来组织语言。

- 以前：用户问 → 模型直接回答 → 可能过时/不准/编造
- 现在：用户问 → 模型生成“调用指令” → 程序执行工具 → 返回结果 → 模型基于结果输出最终回答

## 2. Function Calling 的工作流程
理解这个流程至关重要，因为它是一个多轮往返的过程。

1. 你先告诉模型：我这里有个工具叫 `get_weather`，它能查天气，需要一个参数 `location`。（工具的参数一般用 JSON 来传）
2. 用户发问：“上海今天多冷？”
3. 模型判断：这事不能靠猜，需要查，于是输出类似这样的“需求单”：`get_weather({ "location": "Shanghai" })`
4. 你的程序看到这张“需求单”，就真的去调用天气接口/服务，把结果查出来
5. 程序把查到的结果回给模型，比如 `{ "temp": "5°C" }`
6. 模型把结果翻译成你看得懂的话：比如“上海今天大概 5°C，体感偏冷……”

# MCP

## 1. MCP 解决了什么问题？

- 集成成本高（重复造轮子）：如果你想让 AI 连接 Google Drive、GitHub 和 Slack，开发者必须分别为这三个平台编写不同的对接逻辑。
- 数据孤岛：很多有价值的数据存储在本地文件、私有数据库或特定的企业软件中，AI 很难安全、实时地获取这些上下文。
- 难以跨平台迁移：你为某一个模型开发的插件，往往无法直接在另一个模型或另一个 AI 应用中使用。

MCP 的出现实现了：
- 标准化： 就像 USB 取代了各种奇形怪状的接口，MCP 提供了一套标准化的协议，让模型、应用和服务器之间能够“说同一种语言”。
- 生态复用： 开发者写好一个 MCP Server（如“本地文件读取服务器”），任何支持 MCP 的 AI 客户端（如 Claude Desktop、IDE 等）都能直接调用它。

## 2. MCP 的核心架构
要理解工作流程，首先要了解 MCP 架构中的三个核心角色：
1. MCP Host (宿主/客户端)： 用户使用的 AI 应用（例如 Claude Desktop、Cursor 或自定义的 AI Agent）。它负责发起请求并展示结果。
2. MCP Client (客户端插件)： 运行在 Host 内部，负责与 Server 通信。
3. MCP Server (服务器)： 提供具体能力的轻量级程序。它负责暴露本地资源（如文件、数据库）或远程 API（如 GitHub API）。

## 3. MCP 的工作流程
当你在一个支持 MCP 的 AI 应用中输入指令时，背后的工作流程如下：

### 第一阶段：连接与发现
- 配置： 用户在 Host 中配置 MCP Server 的路径（通常是一个命令或环境变量）。
- 握手： Host 启动 MCP Server，双方通过标准协议（如 JSON-RPC）进行握手，Server 会告诉 Host：“我能提供哪些资源（Resources）、工具（Tools）和提示模板（Prompts）”。

### 第二阶段：任务执行
以“让 AI 总结本地 data.csv 文件”为例：
1. 用户输入： “帮我分析一下桌面上 data.csv 里的数据趋势。”
2. 意图识别： Host（AI 模型）意识到它需要访问本地文件。
3. 发送请求： Host 通过 MCP Client 向对应的 Filesystem MCP Server 发起 read_resource 或 call_tool 请求。
4. 本地处理： MCP Server 在你的本地机器上读取该文件，并将文件内容转化为标准化的文本数据。
5. 返回结果： Server 将数据发回给 Host。
6. 模型推理： Host 将获取到的 CSV 内容放入 AI 的上下文（Context）中。
7. 最终回答： AI 根据这些最新的上下文，给用户生成分析报告。

# Agent Skills
